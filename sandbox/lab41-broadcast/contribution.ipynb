{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forked Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Standard python libraries\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import matplotlib.pylab as plt\n",
    "import functools\n",
    "%matplotlib inline\n",
    "\n",
    "## Magnolia data iteration\n",
    "sys.path.append('../../')\n",
    "from src.features.mixer import FeatureMixer\n",
    "from src.features.wav_iterator import batcher\n",
    "from supervised_iterator_experiment import SupervisedIterator, SupervisedMixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0-rc2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numsources = 2\n",
    "batchsize = 256\n",
    "datashape = (40, 257)\n",
    "embedding_size = 600\n",
    "restore_session=False\n",
    "libridev='/local_data/teams/magnolia/libri-dev.h5'\n",
    "libritrain='/local_data/teams/magnolia/librispeech/processed_train-clean-100.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a supervised mixer and batcher\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervised feature mixer with 3 libridev sources timed at  1.3266749999999998 sec\n"
     ]
    }
   ],
   "source": [
    "if numsources == 3:\n",
    "    mixer = SupervisedMixer([libritrain,libritrain,libritrain], shape=datashape, \n",
    "                         mix_method='add', diffseed=True, return_key=True)\n",
    "else:\n",
    "    mixer = SupervisedMixer([libritrain,libritrain], shape=datashape, \n",
    "                            mix_method='add', diffseed=True, return_key=True)\n",
    "\n",
    "\n",
    "# Check the time\n",
    "tbeg = time.clock()\n",
    "X, Y, I = mixer.get_batch(batchsize)\n",
    "tend = time.clock()\n",
    "print('Supervised feature mixer with 3 libridev sources timed at ', (tend-tbeg), 'sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEURAL NETWORK\n",
    "\n",
    "The lost function takes in as input the variable `Vlast` for last layer ($V_{last}$, where a vector in $V_{last}$ is $v_{l}$). (That's the first couplet lines, where one just makes a tensorflow variable `Vlasttf`.)\n",
    "\n",
    "The actual cost function is the *word2vec* objective function, where samples are positively and negatively sampled and then mixed. Let $A$ be a matrix of \"attractors\", so to speak. (We'll not use that terminology later on.) Then a positively sampled vector $a_p$ and a few negatively sampled ones $a_{n_1}$ and $a_{n_2}$ are all columns in $A$. The loss over a batch $B$ is denoted `tfbatchlo`, and is specified as:\n",
    "\n",
    "$$ \\mathcal{L}(v_{last}) = \\log \\sigma ( v_l^T a_p) + \\sum_j \\log \\sigma( -1 \\cdot v_l^T a_{n_j} )$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scope(function):\n",
    "    attribute = '_cache_' + function.__name__\n",
    "    name = function.__name__\n",
    "\n",
    "    @property\n",
    "    @functools.wraps(function)\n",
    "    def decorator(self):\n",
    "        if not hasattr(self,attribute):\n",
    "            with tf.device(\"/gpu:0\"):\n",
    "                with tf.variable_scope(name):\n",
    "                    setattr(self,attribute,function(self))\n",
    "        return getattr(self,attribute)\n",
    "    \n",
    "    return decorator\n",
    "\n",
    "class L41Broadcast:\n",
    "    def __init__(self, X, Y, F, I, layer_size, embedding_size, num_labels):\n",
    "        \n",
    "        self.Vclass = tf.Variable(tf.random_normal( [embedding_size, num_labels, F], stddev=0.08 ), \n",
    "                                  dtype=tf.float32,\n",
    "                                  name = 'Vclass')\n",
    "        \n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "        self.F = F\n",
    "        self.I = I\n",
    "        \n",
    "        self.layer_size = layer_size\n",
    "        self.embedding_size = embedding_size\n",
    "                \n",
    "        self.network\n",
    "        self.cost\n",
    "        self.optimizer\n",
    "        \n",
    "    \n",
    "    def weight_variable(self,shape):\n",
    "        initial = tf.truncated_normal(shape, stddev=tf.sqrt(2.0/shape[0]))\n",
    "        return tf.Variable(initial)\n",
    "    \n",
    "    def conv1d(self,x, W):\n",
    "        return tf.nn.conv1d(x, W, stride=1, padding='SAME')\n",
    "    \n",
    "    def conv1d_layer(self,in_layer,shape):\n",
    "        weights = self.weight_variable(shape)\n",
    "        biases = self.weight_variable([shape[-1]])\n",
    "        \n",
    "        return self.conv1d(in_layer,weights) + biases\n",
    "    \n",
    "    def BLSTM(self, X, size, scope):\n",
    "        forward_input = X\n",
    "        backward_input = tf.reverse(X, [1])\n",
    "        \n",
    "        with tf.variable_scope('forward_' + scope):\n",
    "            forward_lstm = tf.contrib.rnn.BasicLSTMCell(size//2)\n",
    "            forward_out, f_state = tf.nn.dynamic_rnn(forward_lstm, forward_input, dtype=tf.float32)\n",
    "        \n",
    "        with tf.variable_scope('backward_' + scope):\n",
    "            backward_lstm = tf.contrib.rnn.BasicLSTMCell(size//2)\n",
    "            backward_out, b_state = tf.nn.dynamic_rnn(backward_lstm, backward_input, dtype=tf.float32)\n",
    "        \n",
    "        return tf.concat([forward_out[:,:,:], backward_out[:,::-1,:]], 2)\n",
    "    \n",
    "    @scope\n",
    "    def network(self):\n",
    "        shape = tf.shape(self.X)\n",
    "        \n",
    "        BLSTM_1 = self.BLSTM(self.X, self.layer_size, 'one')\n",
    "        BLSTM_2 = self.BLSTM(BLSTM_1, self.layer_size, 'two')\n",
    "        \n",
    "        feedforward = self.conv1d_layer(BLSTM_2,[1,self.layer_size,self.embedding_size*self.F])\n",
    "        \n",
    "        embedding = tf.reshape(feedforward,[shape[0],shape[1],self.F,self.embedding_size]) \n",
    "        embedding = tf.nn.l2_normalize(embedding,3)\n",
    "        \n",
    "        return embedding\n",
    "    \n",
    "    @scope\n",
    "    def cost(self):        \n",
    "        \n",
    "        Xshape=tf.shape(self.X)\n",
    "        Yshape=tf.shape(self.Y)\n",
    "        \n",
    "        # things that are necessary for the cost function\n",
    "        Vin = self.network\n",
    "        I = tf.expand_dims( self.I, axis=2 )\n",
    "        Y = self.Y\n",
    "        Vclass = self.Vclass\n",
    "        \n",
    "        # l2 normalization\n",
    "        Vclass = tf.nn.l2_normalize(Vclass, 0)\n",
    "        \n",
    "        # gather the appropriate vectors\n",
    "        Vout = tf.gather_nd( tf.transpose(Vclass, perm=[1,2,0]), I )\n",
    "        \n",
    "        # Broadcasted Vi and Vo\n",
    "        Vinbroad = tf.reshape( Vin, [Yshape[0], 1, Yshape[2], Yshape[3], self.embedding_size])\n",
    "        Voutbroad= tf.reshape( Vout, [Yshape[0], Yshape[1], 1, Yshape[3], self.embedding_size] )\n",
    "                \n",
    "        # Correlate all the vectors:\n",
    "        lossfxn = - tf.log( tf.nn.sigmoid( Y * tf.reduce_sum(Vinbroad * Voutbroad, 4) ) )\n",
    "        \n",
    "        # Sum correlations over positive and negative correlations\n",
    "        lossfxn = tf.reduce_sum( lossfxn, 1 )\n",
    "        \n",
    "        # Average over all the batches\n",
    "        lossfxn = tf.reduce_mean( lossfxn, 0)\n",
    "        \n",
    "        # To do: put weight by pre-emphasis or gradient confidence\n",
    "        lossfxn = tf.reduce_mean( lossfxn )\n",
    "        \n",
    "        return lossfxn\n",
    "\n",
    "    @scope\n",
    "    def optimizer(self):\n",
    "        opt = tf.train.AdamOptimizer()\n",
    "        cost = self.cost\n",
    "        return opt.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "F = 257\n",
    "layer_size=600\n",
    "embedding_size=40\n",
    "X = tf.placeholder(\"float\", [None,None,F])\n",
    "Y = tf.placeholder(\"float\", [None, None,None,F])\n",
    "I = tf.placeholder(dtype=tf.int32)\n",
    "\n",
    "num_labels=251\n",
    "\n",
    "model = L41Broadcast(X, Y, F, I, layer_size, embedding_size, num_labels)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "iterations = []\n",
    "costs = []\n",
    "\n",
    "if restore_session:\n",
    "    saver.restore(sess, '/data/fs4/home/kni/magnolia/models/l41-model-2spkr86.h5')\n",
    "\n",
    "print(\"Initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, Cost function = 1.39154"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-57e24a1292e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mXdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_TF\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mXin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mXin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mXin\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mXin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mXin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mXin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/fs4/home/kni/magnolia/repo-karllab41/sandbox/lab41-broadcast/supervised_iterator_experiment.py\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(self, num_samples, out_TF, Y, repeat_labels)\u001b[0m\n\u001b[1;32m    103\u001b[0m         '''\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSupervisedMixer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/fs4/home/kni/magnolia/repo-karllab41/src/features/mixer.py\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(self, batchsize)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterators\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mbatches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# Resultant size of `mixed` is the same as any iterator's batch size as it is the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/fs4/home/kni/magnolia/repo-karllab41/src/features/hdf5_iterator.py\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(self, batchsize)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mtupledata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_key\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/fs4/home/kni/magnolia/repo-karllab41/src/features/hdf5_iterator.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;34m'''Randomly pick a dataset from the available options'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mnum_tries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_tries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tf1.1/lib/python3.5/logging/__init__.py\u001b[0m in \u001b[0;36mgetLogger\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     \"\"\"\n\u001b[1;32m   1781\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1782\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mLogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1783\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1784\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tf1.1/lib/python3.5/logging/__init__.py\u001b[0m in \u001b[0;36mgetLogger\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggerDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggerDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPlaceHolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m                     \u001b[0mph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m                     \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggerClass\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_loggerClass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for iteration in range(1000000):\n",
    "\n",
    "    # Preprocessing\n",
    "    Xdata, Ydata, Idata = mixer.get_batch(batchsize, out_TF=None)    \n",
    "    Xin = np.sqrt( abs(Xdata) )\n",
    "    Xin = (Xin - Xin.min()) / (Xin.max() - Xin.min())\n",
    "\n",
    "    optloss, cost = sess.run([model.optimizer, model.cost], feed_dict={X: Xin, Y:Ydata, I:Idata})\n",
    "    costs += [cost]\n",
    "    sys.stdout.write('\\rIteration '+str(iteration)+', Cost function = '+str(cost))\n",
    "    \n",
    "    if not ((iteration+1) % 1000):\n",
    "        save_path = saver.save(sess, \"/data/fs4/home/kni/magnolia/models/l41-model-2spkr-expt-pos.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def meanfilter(costs):\n",
    "    return np.convolve(np.array(costs), 1/100*np.ones(100), mode='valid')\n",
    "smoothcosts = meanfilter(costs)\n",
    "plt.plot(np.array(smoothcosts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src.utils.clustering_utils import get_cluster_masks\n",
    "from src.features.hdf5_iterator import Hdf5Iterator\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "if False:\n",
    "    if numsources == 3:\n",
    "        longmixer = SupervisedMixer([libritrain,libritrain,libritrain], shape=(200,257), \n",
    "                                    mix_method='add', diffseed=True, return_key=True)\n",
    "    elif numsources == 2:\n",
    "        longmixer = SupervisedMixer([libritrain,libritrain], shape=(100,257), \n",
    "                                    mix_method='add', diffseed=True, return_key=True)\n",
    "\n",
    "\n",
    "# Check the time\n",
    "tbeg = time.clock()\n",
    "Xtest, Ytest, Itest = longmixer.get_batch(2, out_TF=None)\n",
    "Xin = np.sqrt( abs(Xtest) )\n",
    "Xin = (Xin - Xin.min()) / (Xin.max() - Xin.min())\n",
    "\n",
    "tend = time.clock()\n",
    "print('Supervised feature mixer with 3 libridev sources timed at ', (tend-tbeg), 'sec')\n",
    "\n",
    "Vin, Vcl = sess.run([model.network, model.Vclass], feed_dict={X: abs(Xin), Y:Ytest, I:Idata})\n",
    "masks = get_cluster_masks(Vin, 2)\n",
    "\n",
    "plt.figure(figsize=(12,12)); \n",
    "plt.subplot(121); plt.imshow( masks[:,:,0].T, aspect=.2, cmap='bone' )\n",
    "plt.subplot(122); plt.imshow( Ytest[0,0].T, aspect=.2, cmap='bone' )\n",
    "\n",
    "plt.figure(figsize=(12,12)); \n",
    "plt.subplot(121); plt.imshow( masks[:,:,1].T, aspect=.2, cmap='bone' )\n",
    "plt.subplot(122); plt.imshow( Ytest[0,1].T, aspect=.2, cmap='bone' )\n",
    "\n",
    "if numsources == 3:\n",
    "    plt.figure(figsize=(12,12)); \n",
    "    plt.subplot(121); plt.imshow( masks[:,:,2].T, aspect=.2, cmap='bone' )\n",
    "    plt.subplot(122); plt.imshow( Ytest[0,2].T, aspect=.2, cmap='bone' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.features.spectral_features import reconstruct\n",
    "from IPython.display import Audio\n",
    "from IPython.display import display\n",
    "\n",
    "masks = get_cluster_masks(abs(Vin), 2)\n",
    "masks = masks.transpose(2,0,1)\n",
    "Ytest = (Ytest + 1)/2\n",
    "\n",
    "# Stupid hack, there's a better way to do this\n",
    "mask = masks[0]\n",
    "soundshape = reconstruct( (abs(Xtest[0]) * mask), np.angle(Xtest[0]), 10000, 0.0512, 0.0256 ).shape\n",
    "Xsound = np.zeros( (numsources+1, soundshape[0]) )\n",
    "Ysound = np.zeros( (numsources, soundshape[0]) )\n",
    "\n",
    "Xsound[0] = reconstruct( abs(Xtest[0]), Xtest[0], 10000, 0.0512, 0.0256 )\n",
    "for i, mask in enumerate(masks):\n",
    "    Xsound[i+1] = reconstruct( abs(Xtest[0]) * mask, Xtest[0], 10000, 0.0512, 0.0256 )\n",
    "    Ysound[i] = reconstruct( abs(Xtest[0]) * Ytest[0,i], Xtest[0], 10000, 0.0512, 0.0256 )\n",
    "    \n",
    "    \n",
    "print(\"ORIGINAL\")\n",
    "display(Audio(Xsound[0], rate=10000))\n",
    "print(\"IDEAL MASK 1\")\n",
    "display(Audio(Ysound[0], rate=10000))\n",
    "print(\"PREDICTED MASK 1\")\n",
    "display(Audio(Xsound[1], rate=10000))\n",
    "print(\"IDEAL MASK 2\")\n",
    "display(Audio(Ysound[1], rate=10000))\n",
    "print(\"PREDICTED MASK 2\")\n",
    "display(Audio(Xsound[2], rate=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Vclass:0' shape=(40, 251, 257) dtype=float32_ref>,\n",
       " <tf.Variable 'network/forward_one/rnn/basic_lstm_cell/weights:0' shape=(557, 1200) dtype=float32_ref>,\n",
       " <tf.Variable 'network/forward_one/rnn/basic_lstm_cell/biases:0' shape=(1200,) dtype=float32_ref>,\n",
       " <tf.Variable 'network/backward_one/rnn/basic_lstm_cell/weights:0' shape=(557, 1200) dtype=float32_ref>,\n",
       " <tf.Variable 'network/backward_one/rnn/basic_lstm_cell/biases:0' shape=(1200,) dtype=float32_ref>,\n",
       " <tf.Variable 'network/forward_two/rnn/basic_lstm_cell/weights:0' shape=(900, 1200) dtype=float32_ref>,\n",
       " <tf.Variable 'network/forward_two/rnn/basic_lstm_cell/biases:0' shape=(1200,) dtype=float32_ref>,\n",
       " <tf.Variable 'network/backward_two/rnn/basic_lstm_cell/weights:0' shape=(900, 1200) dtype=float32_ref>,\n",
       " <tf.Variable 'network/backward_two/rnn/basic_lstm_cell/biases:0' shape=(1200,) dtype=float32_ref>,\n",
       " <tf.Variable 'network/Variable:0' shape=(1, 600, 10280) dtype=float32_ref>,\n",
       " <tf.Variable 'network/Variable_1:0' shape=(10280,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vcl_30k = sess.run( tf.trainable_variables()[1] )\n",
    "# Vcl_31k = sess.run( tf.trainable_variables()[1] )\n",
    "tf.trainable_variables()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow1.1",
   "language": "python",
   "name": "tf1.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
