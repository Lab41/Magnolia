{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forked Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Standard python libraries\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import matplotlib.pylab as plt\n",
    "import functools\n",
    "%matplotlib inline\n",
    "\n",
    "## Magnolia data iteration\n",
    "sys.path.append('../../')\n",
    "from src.features.mixer import FeatureMixer\n",
    "from src.features.wav_iterator import batcher\n",
    "from supervised_iterator_experiment import SupervisedIterator, SupervisedMixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0-rc2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numsources = 2\n",
    "num_labels = 251\n",
    "batchsize = 64\n",
    "datashape = (40, 257)\n",
    "embedding_size = 600\n",
    "restore_session=False\n",
    "libridev='/local_data/teams/magnolia/libri-dev.h5'\n",
    "libritrain='/local_data/teams/magnolia/librispeech/processed_train-clean-100.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a supervised mixer and batcher\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervised feature mixer with 3 libridev sources timed at  0.34869400000000006 sec\n"
     ]
    }
   ],
   "source": [
    "if numsources == 3:\n",
    "    mixer = SupervisedMixer([libritrain,libritrain,libritrain], shape=datashape, \n",
    "                         mix_method='add', diffseed=True, return_key=True)\n",
    "else:\n",
    "    mixer = SupervisedMixer([libritrain,libritrain], shape=datashape, \n",
    "                            mix_method='add', diffseed=True, return_key=True)\n",
    "\n",
    "\n",
    "# Check the time\n",
    "tbeg = time.clock()\n",
    "X, Y, I = mixer.get_batch(batchsize)\n",
    "tend = time.clock()\n",
    "print('Supervised feature mixer with 3 libridev sources timed at ', (tend-tbeg), 'sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEURAL NETWORK\n",
    "\n",
    "The lost function takes in as input the variable `Vlast` for last layer ($V_{last}$, where a vector in $V_{last}$ is $v_{l}$). (That's the first couplet lines, where one just makes a tensorflow variable `Vlasttf`.)\n",
    "\n",
    "The actual cost function is the *word2vec* objective function, where samples are positively and negatively sampled and then mixed. Let $A$ be a matrix of \"attractors\", so to speak. (We'll not use that terminology later on.) Then a positively sampled vector $a_p$ and a few negatively sampled ones $a_{n_1}$ and $a_{n_2}$ are all columns in $A$. The loss over a batch $B$ is denoted `tfbatchlo`, and is specified as:\n",
    "\n",
    "$$ \\mathcal{L}(v_{last}) = \\log \\sigma ( v_l^T a_p) + \\sum_j \\log \\sigma( -1 \\cdot v_l^T a_{n_j} )$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scope(function):\n",
    "    attribute = '_cache_' + function.__name__\n",
    "    name = function.__name__\n",
    "\n",
    "    @property\n",
    "    @functools.wraps(function)\n",
    "    def decorator(self):\n",
    "        if not hasattr(self,attribute):\n",
    "            with tf.device(\"/gpu:0\"):\n",
    "                with tf.variable_scope(name):\n",
    "                    setattr(self,attribute,function(self))\n",
    "        return getattr(self,attribute)\n",
    "    \n",
    "    return decorator\n",
    "\n",
    "class L41Convolve:\n",
    "    def __init__(self, X, Y, F, layer_size, embedding_size, num_labels):\n",
    "        \n",
    "        self.Vclass = tf.Variable(tf.random_normal([1, 1, embedding_size, num_labels], stddev=0.1),\n",
    "                                 dtype=tf.float32, name = 'Vclass')\n",
    "        \n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "        self.F = F\n",
    "        \n",
    "        self.layer_size = layer_size\n",
    "        self.embedding_size = embedding_size\n",
    "                \n",
    "        self.network\n",
    "        self.cost\n",
    "        self.optimizer\n",
    "        \n",
    "    \n",
    "    def weight_variable(self,shape):\n",
    "        initial = tf.truncated_normal(shape, stddev=tf.sqrt(2.0/shape[0]))\n",
    "        return tf.Variable(initial)\n",
    "    \n",
    "    def conv1d(self,x, W):\n",
    "        return tf.nn.conv1d(x, W, stride=1, padding='SAME')\n",
    "    \n",
    "    def conv1d_layer(self,in_layer,shape):\n",
    "        weights = self.weight_variable(shape)\n",
    "        biases = self.weight_variable([shape[-1]])\n",
    "        \n",
    "        return self.conv1d(in_layer,weights) + biases\n",
    "    \n",
    "    def BLSTM(self, X, size, scope):\n",
    "        forward_input = X\n",
    "        backward_input = tf.reverse(X, [1])\n",
    "        \n",
    "        with tf.variable_scope('forward_' + scope):\n",
    "            forward_lstm = tf.contrib.rnn.BasicLSTMCell(size//2)\n",
    "            forward_out, f_state = tf.nn.dynamic_rnn(forward_lstm, forward_input, dtype=tf.float32)\n",
    "        \n",
    "        with tf.variable_scope('backward_' + scope):\n",
    "            backward_lstm = tf.contrib.rnn.BasicLSTMCell(size//2)\n",
    "            backward_out, b_state = tf.nn.dynamic_rnn(backward_lstm, backward_input, dtype=tf.float32)\n",
    "        \n",
    "        return tf.concat([forward_out[:,:,:], backward_out[:,::-1,:]], 2)\n",
    "    \n",
    "    @scope\n",
    "    def network(self):\n",
    "        shape = tf.shape(self.X)\n",
    "        \n",
    "        BLSTM_1 = self.BLSTM(self.X, self.layer_size, 'one')\n",
    "        BLSTM_2 = self.BLSTM(BLSTM_1, self.layer_size, 'two')\n",
    "        \n",
    "        feedforward = self.conv1d_layer(BLSTM_2,[1,self.layer_size,self.embedding_size*self.F])\n",
    "        \n",
    "        embedding = tf.reshape(feedforward,[shape[0],shape[1],self.F,self.embedding_size]) \n",
    "        embedding = tf.nn.l2_normalize(embedding,3)\n",
    "        \n",
    "        return embedding\n",
    "    \n",
    "    @scope\n",
    "    def cost(self):        \n",
    "        \n",
    "        Xshape=tf.shape(self.X)\n",
    "        Yshape=tf.shape(self.Y)\n",
    "        \n",
    "        # Vin is B x T x F x E\n",
    "        Vin = self.network\n",
    "        self.Xcorr = Y * tf.nn.conv2d( Vin, self.Vclass, [1,1,1,1], padding='VALID' )\n",
    "        self.UnitCost = tf.reduce_sum( -abs(Y)*tf.log(tf.sigmoid( self.Xcorr )), 3 )\n",
    "        lossfxn = tf.reduce_mean( self.UnitCost )\n",
    "        \n",
    "        return lossfxn\n",
    "\n",
    "    @scope\n",
    "    def optimizer(self):\n",
    "        opt = tf.train.AdamOptimizer()\n",
    "        cost = self.cost\n",
    "        return opt.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "F = 257\n",
    "layer_size=600\n",
    "embedding_size=40\n",
    "X = tf.placeholder(\"float\", [None,None,F])\n",
    "Y = tf.placeholder(\"float\", [None, None,F,num_labels])\n",
    "\n",
    "num_labels=251\n",
    "\n",
    "model = L41Convolve(X, Y, F, layer_size, embedding_size, num_labels)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "iterations = []\n",
    "costs = []\n",
    "\n",
    "if restore_session:\n",
    "    saver.restore(sess, '/data/fs4/home/kni/magnolia/models/l41-model-2spkr-convolve.h5')\n",
    "\n",
    "print(\"Initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 25, Cost function = 1.38702"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-01ed6989d021>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     optloss, vin, xcorr, cost, unitcost = sess.run([model.optimizer, model.network, \n\u001b[1;32m     15\u001b[0m                                           model.Xcorr, model.cost, model.UnitCost], \n\u001b[0;32m---> 16\u001b[0;31m                                          feed_dict={X: Xin, Y:Ymask})\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mcosts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\rIteration '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m', Cost function = '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tf1.1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    784\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 786\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    787\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tf1.1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfeed_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[0;32m/opt/conda/envs/tf1.1/lib/python3.5/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \"\"\"\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for iteration in range(1000000):\n",
    "\n",
    "    # Preprocessing\n",
    "    Xdata, Ydata, Idata = mixer.get_batch(batchsize, out_TF=None)    \n",
    "    Xin = np.sqrt( abs(Xdata) )\n",
    "    Xin = (Xin - Xin.min()) / (Xin.max() - Xin.min())\n",
    "    \n",
    "    Ymask = np.zeros((batchsize,*datashape,num_labels))\n",
    "    for i in range(batchsize):\n",
    "        for j in range(numsources):\n",
    "            Ymask[i,:,:,Idata[i,j]] = Ydata[i,j]\n",
    "\n",
    "    # optloss, cost = sess.run([model.optimizer, model.cost], feed_dict={X: Xin, Y:Ymask})\n",
    "    optloss, vin, xcorr, cost, unitcost = sess.run([model.optimizer, model.network, \n",
    "                                          model.Xcorr, model.cost, model.UnitCost], \n",
    "                                         feed_dict={X: Xin, Y:Ymask})\n",
    "    costs += [cost]\n",
    "    sys.stdout.write('\\rIteration '+str(iteration)+', Cost function = '+str(cost))\n",
    "    \n",
    "    if not ((iteration+1) % 1000):\n",
    "        save_path = saver.save(sess, \"/data/fs4/home/kni/magnolia/models/l41-model-2spkr-expt-pos.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 40, 257, 40)\n",
      "(1, 1, 40, 251)\n",
      "(64, 40, 257, 251)\n",
      "(64, 40, 257, 251)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00074534614795120058"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vout = sess.run(model.Vclass)\n",
    "print( vin.shape )\n",
    "print( vout.shape )\n",
    "print( xcorr.shape )\n",
    "print( Ymask.shape )\n",
    "\n",
    "\n",
    "( Ymask * xcorr ).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1648106d30>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f162877d208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def meanfilter(costs):\n",
    "    return np.convolve(np.array(costs), 1/100*np.ones(100), mode='valid')\n",
    "smoothcosts = meanfilter(costs)\n",
    "plt.plot(np.array(costs))\n",
    "plt.plot(np.array(smoothcosts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src.utils.clustering_utils import get_cluster_masks\n",
    "from src.features.hdf5_iterator import Hdf5Iterator\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "if False:\n",
    "    if numsources == 3:\n",
    "        longmixer = SupervisedMixer([libritrain,libritrain,libritrain], shape=(200,257), \n",
    "                                    mix_method='add', diffseed=True, return_key=True)\n",
    "    elif numsources == 2:\n",
    "        longmixer = SupervisedMixer([libritrain,libritrain], shape=(100,257), \n",
    "                                    mix_method='add', diffseed=True, return_key=True)\n",
    "\n",
    "\n",
    "# Check the time\n",
    "tbeg = time.clock()\n",
    "Xtest, Ytest, Itest = longmixer.get_batch(2, out_TF=None)\n",
    "Xin = np.sqrt( abs(Xtest) )\n",
    "Xin = (Xin - Xin.min()) / (Xin.max() - Xin.min())\n",
    "\n",
    "tend = time.clock()\n",
    "print('Supervised feature mixer with 3 libridev sources timed at ', (tend-tbeg), 'sec')\n",
    "\n",
    "Vin, Vcl = sess.run([model.network, model.Vclass], feed_dict={X: abs(Xin), Y:Ytest, I:Idata})\n",
    "masks = get_cluster_masks(Vin, 2)\n",
    "\n",
    "plt.figure(figsize=(12,12)); \n",
    "plt.subplot(121); plt.imshow( masks[:,:,0].T, aspect=.2, cmap='bone' )\n",
    "plt.subplot(122); plt.imshow( Ytest[0,0].T, aspect=.2, cmap='bone' )\n",
    "\n",
    "plt.figure(figsize=(12,12)); \n",
    "plt.subplot(121); plt.imshow( masks[:,:,1].T, aspect=.2, cmap='bone' )\n",
    "plt.subplot(122); plt.imshow( Ytest[0,1].T, aspect=.2, cmap='bone' )\n",
    "\n",
    "if numsources == 3:\n",
    "    plt.figure(figsize=(12,12)); \n",
    "    plt.subplot(121); plt.imshow( masks[:,:,2].T, aspect=.2, cmap='bone' )\n",
    "    plt.subplot(122); plt.imshow( Ytest[0,2].T, aspect=.2, cmap='bone' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.features.spectral_features import reconstruct\n",
    "from IPython.display import Audio\n",
    "from IPython.display import display\n",
    "\n",
    "masks = get_cluster_masks(abs(Vin), 2)\n",
    "masks = masks.transpose(2,0,1)\n",
    "Ytest = (Ytest + 1)/2\n",
    "\n",
    "# Stupid hack, there's a better way to do this\n",
    "mask = masks[0]\n",
    "soundshape = reconstruct( (abs(Xtest[0]) * mask), np.angle(Xtest[0]), 10000, 0.0512, 0.0256 ).shape\n",
    "Xsound = np.zeros( (numsources+1, soundshape[0]) )\n",
    "Ysound = np.zeros( (numsources, soundshape[0]) )\n",
    "\n",
    "Xsound[0] = reconstruct( abs(Xtest[0]), Xtest[0], 10000, 0.0512, 0.0256 )\n",
    "for i, mask in enumerate(masks):\n",
    "    Xsound[i+1] = reconstruct( abs(Xtest[0]) * mask, Xtest[0], 10000, 0.0512, 0.0256 )\n",
    "    Ysound[i] = reconstruct( abs(Xtest[0]) * Ytest[0,i], Xtest[0], 10000, 0.0512, 0.0256 )\n",
    "    \n",
    "    \n",
    "print(\"ORIGINAL\")\n",
    "display(Audio(Xsound[0], rate=10000))\n",
    "print(\"IDEAL MASK 1\")\n",
    "display(Audio(Ysound[0], rate=10000))\n",
    "print(\"PREDICTED MASK 1\")\n",
    "display(Audio(Xsound[1], rate=10000))\n",
    "print(\"IDEAL MASK 2\")\n",
    "display(Audio(Ysound[1], rate=10000))\n",
    "print(\"PREDICTED MASK 2\")\n",
    "display(Audio(Xsound[2], rate=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vcl_30k = sess.run( tf.trainable_variables()[1] )\n",
    "# Vcl_31k = sess.run( tf.trainable_variables()[1] )\n",
    "tf.trainable_variables()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow1.1",
   "language": "python",
   "name": "tf1.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
