{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append('Magnolia/sandbox/BLSTM-DC/')\n",
    "sys.path.append('Magnolia/src/utils')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from deep_clustering_model import DeepClusteringModel\n",
    "from clustering_utils import clustering_separate, get_cluster_masks\n",
    "\n",
    "from magnolia.features.mixer import FeatureMixer\n",
    "from magnolia.features.spectral_features import istft\n",
    "from magnolia.features.data_preprocessing import undo_preemphasis\n",
    "from magnolia.utils.bss_eval import bss_eval_sources\n",
    "\n",
    "import IPython\n",
    "from IPython.display import Audio\n",
    "from matplotlib import pyplot as plt\n",
    "fig_size = [0,0]\n",
    "fig_size[0] = 8\n",
    "fig_size[1] = 4\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Size of BLSTM layers\n",
    "layer_size = 600\n",
    "\n",
    "# Size of embedding vectors\n",
    "K = 40\n",
    "\n",
    "# Size of training batches T = #windows F = #Frequency bins\n",
    "T = 40\n",
    "F = 257\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 512\n",
    "\n",
    "# STFT parameters used\n",
    "sample_rate = 10e3\n",
    "window_size = 0.0512\n",
    "overlap = 0.0256\n",
    "fft_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create feature mixes for both the training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = 'Data/librispeech/processed_train-clean-100.h5'\n",
    "validation_data = 'Data/librispeech/processed_dev_clean.h5'\n",
    "\n",
    "train_mixer = FeatureMixer([train_data,train_data], shape=(T,None))\n",
    "validation_mixer = FeatureMixer([validation_data,validation_data], shape=(T,None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for creating training batches and dealing with spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_spectrogram(spectrogram):\n",
    "    mag_spec = np.abs(spectrogram)\n",
    "    phases = np.unwrap(np.angle(spectrogram))\n",
    "    \n",
    "    mag_spec = np.sqrt(mag_spec)\n",
    "    M = mag_spec.max()\n",
    "    m = mag_spec.min()\n",
    "    \n",
    "    return (mag_spec - m)/(M - m), phases\n",
    "    \n",
    "\n",
    "def gen_batch(mixer,batch_size):\n",
    "    X = np.zeros((batch_size,T,F))\n",
    "    phases = np.zeros((batch_size,T,F))\n",
    "    y = np.zeros((batch_size,T,F,2))\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        data = next(mixer)\n",
    "        \n",
    "        X[i], _ = scale_spectrogram(data[0])\n",
    "        phases[i] = np.unwrap(np.angle(data[0]))\n",
    "        y[i,:,:,0] = 1/2*(np.sign(np.abs(data[1]) - np.abs(data[2])) + 1)\n",
    "        y[i,:,:,1] = 1 - y[i,:,:,0]\n",
    "    return X, y, phases\n",
    "\n",
    "def invert_spectrogram(magnitude,phase):\n",
    "    return istft(np.square(magnitude)*np.exp(phase*1.0j),sample_rate,None,overlap,two_sided=False,fft_size=fft_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a sample from the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_vala, y_vala, phases = gen_batch(validation_mixer,10*batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load an instance of the deep clustering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = DeepClusteringModel()\n",
    "model.load('models/magnolia/deep_clustering.ckpt')\n",
    "\n",
    "iterations = []\n",
    "costs = []\n",
    "\n",
    "t_costs = []\n",
    "v_costs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model on batches from the training dataset\n",
    "\n",
    "Plot the error on the training set and the validation sample every so often"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    start = iterations[-1]\n",
    "except:\n",
    "    start = 0\n",
    "\n",
    "for i in range(200000):\n",
    "    X_train, y_train, phases = gen_batch(train_mixer,batch_size)\n",
    "    c = model.train_on_batch(X_train, y_train)\n",
    "    costs.append(c)\n",
    "    \n",
    "    if (i+1) % 10 == 0:\n",
    "        IPython.display.clear_output(wait=True)\n",
    "        c_v = model.get_cost(X_vala, y_vala)\n",
    "        \n",
    "        if len(iterations):\n",
    "            if c_v < min(v_costs) and iterations[-1] > 0:\n",
    "                print(\"Saving the model because c_v is\", c_v)\n",
    "                model.save('models/magnolia/deep_clustering.ckpt')\n",
    "            \n",
    "        t_costs.append(np.mean(costs))\n",
    "        v_costs.append(c_v)\n",
    "        iterations.append(i + start)\n",
    "        \n",
    "        length = len(iterations)\n",
    "        cutoff = int(0.5*length)\n",
    "        \n",
    "        f, (ax1, ax2) = plt.subplots(2,1)\n",
    "        \n",
    "        ax1.plot(iterations,t_costs)\n",
    "        ax1.plot(iterations,v_costs)\n",
    "        \n",
    "        y_u = max(max(t_costs[cutoff:]),max(v_costs[cutoff:]))\n",
    "        y_l = min(min(t_costs[cutoff:]),min(v_costs[cutoff:]))\n",
    "        ax2.set_ylim(y_l,y_u)\n",
    "        \n",
    "        ax2.plot(iterations[cutoff:], t_costs[cutoff:])\n",
    "        ax2.plot(iterations[cutoff:], v_costs[cutoff:])\n",
    "        plt.show()\n",
    "        print(\"Cost is\", c_v)\n",
    "        costs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length = len(iterations)\n",
    "cutoff = int(0.5*length)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2,1)\n",
    "\n",
    "ax1.plot(iterations,t_costs)\n",
    "ax1.plot(iterations,v_costs)\n",
    "\n",
    "y_u = max(max(t_costs[cutoff:]),max(v_costs[cutoff:]))\n",
    "y_l = min(min(t_costs[cutoff:]),min(v_costs[cutoff:]))\n",
    "ax2.set_ylim(y_l,y_u)\n",
    "\n",
    "ax2.plot(iterations[cutoff:], t_costs[cutoff:])\n",
    "ax2.plot(iterations[cutoff:], v_costs[cutoff:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listen to an example separation from the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "long_mixer = FeatureMixer([validation_data,validation_data], shape=(5*T,None)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = next(long_mixer)\n",
    "spec = data[0]\n",
    "signal = istft(spec,sample_rate,None,overlap,two_sided=False,fft_size=512)\n",
    "signal = undo_preemphasis(signal)\n",
    "\n",
    "Audio(signal,rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sources = clustering_separate(signal,sample_rate,model,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Audio(sources[0], rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Audio(sources[1], rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the the learned affinity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ex, y_ex, phases = gen_batch(validation_mixer,1)\n",
    "vectors = model.get_vectors(X_ex)\n",
    "\n",
    "res = vectors[0].reshape((T*F,K))\n",
    "resa = y_ex[0].reshape((T*F,2))\n",
    "\n",
    "A = resa @ resa.T\n",
    "B = (res @ res.T)\n",
    "\n",
    "plt.matshow(A[0:6000,0:6000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.matshow(B[0:6000,0:6000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.matshow(np.square(B[0:6000,0:6000] - 1/2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate BSS metrics on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = 'Data/librispeech/processed_test_clean.h5'\n",
    "test_mixer = FeatureMixer([test_data,test_data], shape=(T,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test, y_test, _ = gen_batch(test_mixer, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bss_eval_batch(mixer, num_sources):\n",
    "    data = next(mixer)\n",
    "    \n",
    "    mixes = [invert_spectrogram(np.abs(data[0]),np.unwrap(np.angle(data[0]))) for i in range(1,num_sources + 1)]\n",
    "    sources = [invert_spectrogram(np.abs(data[i]),np.unwrap(np.angle(data[i]))) for i in range(1,num_sources + 1)]\n",
    "    \n",
    "    mixes = [undo_preemphasis(mix) for mix in mixes]\n",
    "    sources = [undo_preemphasis(source) for source in sources]\n",
    "    \n",
    "    input_mix = np.stack(mixes)\n",
    "    reference_sources = np.stack(sources)\n",
    "    estimated_sources = clustering_separate(mixes[0],1e4,model,num_sources)\n",
    "    \n",
    "    do_nothing = bss_eval_sources(reference_sources, input_mix)\n",
    "    do_something = bss_eval_sources(reference_sources, estimated_sources)\n",
    "    \n",
    "    sdr = do_something[0] - do_nothing[0]\n",
    "    sir = do_something[1] - do_nothing[1]\n",
    "    sar = do_something[2] - do_nothing[2]\n",
    "    \n",
    "    return {'SDR': sdr, 'SIR': sir, 'SAR': sar}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFRNN",
   "language": "python",
   "name": "tfrnn"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
