{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append('../../')\n",
    "\n",
    "from src.dnnseparate.L41model import L41Model\n",
    "\n",
    "from src.utils.clustering_utils import clustering_separate, get_cluster_masks, process_signal\n",
    "\n",
    "from src.features.mixer import FeatureMixer\n",
    "from src.features.supervised_iterator import SupervisedIterator, SupervisedMixer\n",
    "from src.features.hdf5_iterator import SplitsIterator\n",
    "from src.features.spectral_features import istft\n",
    "from src.features.data_preprocessing import undo_preemphasis\n",
    "from src.utils.bss_eval import bss_eval_sources\n",
    "\n",
    "import IPython\n",
    "from IPython.display import Audio\n",
    "from matplotlib import pyplot as plt\n",
    "fig_size = [0,0]\n",
    "fig_size[0] = 8\n",
    "fig_size[1] = 4\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up data I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fft_size = 512\n",
    "\n",
    "numsources = 2\n",
    "batchsize = 256\n",
    "datashape = (40, 257)\n",
    "embedding_size = 600\n",
    "libridev='/local_data/teams/magnolia/librispeech/processed_dev_clean.h5'\n",
    "libritrain='/local_data/teams/magnolia/librispeech/processed_train-clean-100.h5'\n",
    "# libritest='Data/librispeech/processed_test_clean.h5'\n",
    "\n",
    "with open('../../data/librispeech/authors/train-clean-100-F.txt','r') as speakers:\n",
    "    speaker_keys = speakers.read().splitlines()\n",
    "    in_set_F = speakers.read().splitlines()\n",
    "    \n",
    "with open('../../data/librispeech/authors/train-clean-100-M.txt','r') as speakers:\n",
    "    speaker_keys += speakers.read().splitlines()\n",
    "    in_set_M = speakers.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "siterator = SplitsIterator([0.8,0.1,0.1], libritrain, speaker_keys=speaker_keys, shape=datashape, return_key=True)\n",
    "siterator.set_split(0)\n",
    "\n",
    "mixer = SupervisedMixer([siterator,siterator], shape=datashape, \n",
    "                        mix_method='add', diffseed=True)\n",
    "\n",
    "tbeg = time.clock()\n",
    "X, Y, I = mixer.get_batch(batchsize, out_TF=None)\n",
    "Y = Y.reshape(batchsize,2,datashape[0],datashape[1])\n",
    "Y = Y.transpose([0,2,3,1])\n",
    "tend = time.clock()\n",
    "print('Supervised feature mixer with 3 libridev sources timed at ', (tend-tbeg), 'sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Generate some validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "siterator.set_split(1)\n",
    "Xdv, Ydv, Idv = mixer.get_batch(batchsize, out_TF=None)\n",
    "Ydv = Ydv.reshape(batchsize,2,datashape[0],datashape[1])\n",
    "Ydv = Ydv.transpose(0,2,3,1)\n",
    "Xinv = np.sqrt(Xdv)\n",
    "Xinv = (Xinv - Xinv.min())/(Xinv.max() - Xinv.min())\n",
    "siterator.set_split(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an instance of Lab41's model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = L41Model(nonlinearity='tanh')\n",
    "model.initialize()\n",
    "\n",
    "iterations = []\n",
    "costs = []\n",
    "\n",
    "t_costs = []\n",
    "v_costs = []\n",
    "modeltimer = []\n",
    "\n",
    "last_saved = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.load('models/magnolia/lab41_model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    start = iterations[-1]\n",
    "except:\n",
    "    start = 0\n",
    "\n",
    "    \n",
    "siterator.set_split(0)\n",
    "for i in range(2000000):\n",
    "    \n",
    "    Xdata, Ydata, Idata = mixer.get_batch(batchsize, out_TF=None)\n",
    "    Ydata = Ydata.reshape(batchsize,2,datashape[0],datashape[1])\n",
    "    Ydata = Ydata.transpose(0,2,3,1)\n",
    "    \n",
    "    Xin = np.sqrt(np.abs(Xdata))\n",
    "    Xin = (Xin - Xin.min())/(Xin.max() - Xin.min())\n",
    "    \n",
    "    tbegin = time.clock()\n",
    "    c = model.train_on_batch(Xin,Ydata,Idata)\n",
    "    modeltimer += [ time.clock()-tbegin ]\n",
    "\n",
    "    costs.append(c)\n",
    "    \n",
    "    if (i+1) % 10 == 0:\n",
    "        IPython.display.clear_output(wait=True)\n",
    "        c_v = model.get_cost(Xinv, Ydv, Idv)\n",
    "        \n",
    "        try:\n",
    "            if c_v < min(v_costs) and len(iterations) > 0:\n",
    "                print(\"Saving the model because c_v is\", min(v_costs) - c_v, \"below the old min.\")\n",
    "                model.save('lab41_model-x.ckpt')\n",
    "                last_saved = iterations[-1]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        t_costs.append(np.mean(costs))\n",
    "        v_costs.append(c_v)\n",
    "        \n",
    "        iterations.append(i + 1 + start)\n",
    "        \n",
    "        length = len(iterations)\n",
    "        cutoff = int(0.5*length)\n",
    "        lowline = [min(v_costs)]*len(iterations)\n",
    "        \n",
    "        f, (ax1, ax2) = plt.subplots(2,1)\n",
    "        \n",
    "        ax1.plot(iterations,t_costs)\n",
    "        ax1.plot(iterations,v_costs)\n",
    "        ax1.plot(iterations,lowline)\n",
    "        \n",
    "        y_u = max(max(t_costs[cutoff:]),max(v_costs[cutoff:]))\n",
    "        y_l = min(min(t_costs[cutoff:]),min(v_costs[cutoff:]))\n",
    "        \n",
    "        ax2.set_ylim(y_l,y_u)\n",
    "        \n",
    "        ax2.plot(iterations[cutoff:], t_costs[cutoff:])\n",
    "        ax2.plot(iterations[cutoff:], v_costs[cutoff:])\n",
    "        ax2.plot(iterations[cutoff:], lowline[cutoff:])\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Cost on batch\", iterations[-1], \"is\", c_v)\n",
    "        print(\"Last saved\",iterations[-1]-last_saved,\"iterations ago.\")\n",
    "        costs = []\n",
    "        \n",
    "        if iterations[-1]-last_saved > 100000:\n",
    "            print(\"Done!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save('lab41_model-x-run-may-3.ckpt')\n",
    "np.savez( 'lab41-unnormalized-run-may-3.npz', modeltimer=modeltimer, costs=costs, \n",
    "         v_costs=v_costs, t_costs=t_costs, iterations=iterations )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lastsaved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a sample and listen to the results on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "libridev='/local_data/teams/magnolia/librispeech/processed_dev-clean.h5'\n",
    "sample_rate = 1e4\n",
    "overlap = 0.0256\n",
    "long_mixer = FeatureMixer([libridev,libridev], shape=(200,None)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = next(long_mixer)\n",
    "spec = data[0]\n",
    "signal = istft(spec,sample_rate,None,overlap,two_sided=False,fft_size=512)\n",
    "signal = undo_preemphasis(signal)\n",
    "\n",
    "Audio(signal,rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sources = clustering_separate(signal,sample_rate,model,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Audio(sources[0], rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Audio(sources[1], rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spectrogram, vectors = process_signal(signal,sample_rate,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.matshow(np.sqrt(np.abs(spectrogram)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "masks = get_cluster_masks(vectors,2)\n",
    "plt.matshow(masks[:,:,0].T, origin='lower', cmap='bone')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Check the affinity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xdata, Ydata, Idata = mixer.get_batch(1, out_TF=None)\n",
    "Ydata = Ydata.reshape(1,2,datashape[0],datashape[1])\n",
    "Ydata = Ydata.transpose(0,2,3,1)\n",
    "\n",
    "Xin = np.sqrt(np.abs(Xdata))\n",
    "Xin = (Xin - Xin.min())/(Xin.max() - Xin.min())\n",
    "\n",
    "vectors = model.get_vectors(Xin)\n",
    "A = vectors[0].reshape(40*257,40)@vectors[0].reshape(40*257,40).T\n",
    "\n",
    "resa = ((1+Ydata[0])/2).reshape((40*257,2))\n",
    "B =  resa @ resa.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.matshow(A[0:5000,0:5000],vmin=0,vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.matshow(B[0:5000,0:5000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def invert_spectrogram(magnitude,phase):\n",
    "    return istft(np.square(magnitude)*np.exp(phase*1.0j),sample_rate,None,overlap,two_sided=False,fft_size=fft_size)\n",
    "\n",
    "def bss_eval_sample(mixer, num_sources):\n",
    "    data = next(mixer)\n",
    "    \n",
    "    mixes = [invert_spectrogram(np.abs(data[0]),np.unwrap(np.angle(data[0]))) for i in range(1,num_sources + 1)]\n",
    "    sources = [invert_spectrogram(np.abs(data[i][1]),np.unwrap(np.angle(data[i][1]))) for i in range(1,num_sources + 1)]\n",
    "    \n",
    "    mixes = [undo_preemphasis(mix) for mix in mixes]\n",
    "    sources = [undo_preemphasis(source) for source in sources]\n",
    "    \n",
    "    input_mix = np.stack(mixes)\n",
    "    reference_sources = np.stack(sources)\n",
    "    estimated_sources = clustering_separate(mixes[0],1e4,model,num_sources)\n",
    "    \n",
    "    do_nothing = bss_eval_sources(reference_sources, input_mix)\n",
    "    do_something = bss_eval_sources(reference_sources, estimated_sources)\n",
    "    \n",
    "    sdr = do_something[0] - do_nothing[0]\n",
    "    sir = do_something[1] - do_nothing[1]\n",
    "    sar = do_something[2] - do_nothing[2]\n",
    "    \n",
    "    return {'SDR': sdr, 'SIR': sir, 'SAR': sar}\n",
    "\n",
    "def bss_eval(mixer, num_sources, num_samples):\n",
    "    SDR = np.zeros(num_samples)\n",
    "    SIR = np.zeros(num_samples)\n",
    "    SAR = np.zeros(num_samples)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        evals = bss_eval_sample(mixer, 2)\n",
    "        SDR[i] = 1/(2)*(evals['SDR'][0] + evals['SDR'][1])\n",
    "        SIR[i] = 1/(2)*(evals['SIR'][0] + evals['SIR'][1])\n",
    "        SAR[i] = 1/(2)*(evals['SAR'][0] + evals['SAR'][1])\n",
    "    \n",
    "    return SDR, SIR, SAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate BSS metrics on the inset all subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "siterator.set_split(2)\n",
    "\n",
    "samples = 500\n",
    "SDR,SIR,SAR = bss_eval(mixer, 2, samples)\n",
    "\n",
    "print(np.mean(SDR))\n",
    "print(np.std(SDR)/np.sqrt(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate BSS metrics on the FF inset subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "siterator.set_split(2)\n",
    "siterator.speaker_subset(in_set_F)\n",
    "\n",
    "samples = 500\n",
    "SDR,SIR,SAR = bss_eval(mixer, 2, samples)\n",
    "\n",
    "print(np.mean(SDR))\n",
    "print(np.std(SDR)/np.sqrt(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate BSS metrics on the MM inset subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "siterator.set_split(2)\n",
    "siterator.speaker_subset(in_set_M)\n",
    "\n",
    "samples = 500\n",
    "SDR,SIR,SAR = bss_eval(mixer, 2, samples)\n",
    "\n",
    "print(np.mean(SDR))\n",
    "print(np.std(SDR)/np.sqrt(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate BSS metrics on the FM inset subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "siterator2 = SplitsIterator([0.8,0.1,0.1], libritrain, speaker_keys=speaker_keys, shape=datashape, return_key=True)\n",
    "\n",
    "siterator.set_split(2)\n",
    "siterator2.set_split(2)\n",
    "\n",
    "siterator.speaker_subset(in_set_F)\n",
    "siterator2.speaker_subset(in_set_M)\n",
    "\n",
    "FMmixer = SupervisedMixer([siterator,siterator2], shape=datashape, \n",
    "                        mix_method='add', diffseed=True)\n",
    "\n",
    "samples = 500\n",
    "SDR,SIR,SAR = bss_eval(FMmixer, 2, samples)\n",
    "\n",
    "print(np.mean(SDR))\n",
    "print(np.std(SDR)/np.sqrt(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create mixers for out of set FF FM MM, all, speaker mixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('Magnolia/data/librispeech/authors/test-clean-F.txt','r') as speakers:\n",
    "    out_set_F = speakers.read().splitlines()\n",
    "\n",
    "with open('Magnolia/data/librispeech/authors/test-clean-M.txt','r') as speakers:\n",
    "    out_set_M = speakers.read().splitlines()\n",
    "\n",
    "all_speakers = out_set_F + out_set_M\n",
    "\n",
    "Fiterator = SplitsIterator([1], libritest, speaker_keys=out_set_F, shape=datashape, return_key=True)\n",
    "Fiterator.set_split(0)\n",
    "Miterator = SplitsIterator([1], libritest, speaker_keys=out_set_M, shape=datashape, return_key=True)\n",
    "Miterator.set_split(0)\n",
    "Aiterator = SplitsIterator([1], libritest, speaker_keys=all_speakers, shape=datashape, return_key=True)\n",
    "\n",
    "outsetFFmixer = SupervisedMixer([Fiterator,Fiterator], shape=datashape, \n",
    "                        mix_method='add', diffseed=True)\n",
    "outsetFMmixer = SupervisedMixer([Fiterator,Miterator], shape=datashape, \n",
    "                        mix_method='add', diffseed=True)\n",
    "outsetMMmixer = SupervisedMixer([Miterator,Miterator], shape=datashape, \n",
    "                        mix_method='add', diffseed=True)\n",
    "outsetAAmixer = SupervisedMixer([Aiterator,Aiterator], shape=datashape, \n",
    "                        mix_method='add', diffseed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples = 500\n",
    "SDR,SIR,SAR = bss_eval(outsetFFmixer, 2, samples)\n",
    "\n",
    "print(np.mean(SDR))\n",
    "print(np.std(SDR)/np.sqrt(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples = 500\n",
    "SDR,SIR,SAR = bss_eval(outsetFMmixer, 2, samples)\n",
    "\n",
    "print(np.mean(SDR))\n",
    "print(np.std(SDR)/np.sqrt(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples = 500\n",
    "SDR,SIR,SAR = bss_eval(outsetMMmixer, 2, samples)\n",
    "\n",
    "print(np.mean(SDR))\n",
    "print(np.std(SDR)/np.sqrt(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples = 500\n",
    "SDR,SIR,SAR = bss_eval(outsetAAmixer, 2, samples)\n",
    "\n",
    "print(np.mean(SDR))\n",
    "print(np.std(SDR)/np.sqrt(samples))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "tensorflow1.1",
   "language": "python",
   "name": "tf1.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
